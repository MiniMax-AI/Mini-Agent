"""
Multi-Agent Orchestration Demo - å¤šä»£ç†åè°ƒæ¼”ç¤º

å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¤šä»£ç†ç³»ç»Ÿå®Œæˆå¤æ‚å¼€å‘ä»»åŠ¡ã€‚
è¿™æ˜¯ Mini-Agent v0.6.0 çš„æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤ºã€‚

ä¸»è¦æ¼”ç¤ºå†…å®¹ï¼š
1. å¤æ‚ä»»åŠ¡çš„åè°ƒå¤„ç†
2. å¹¶è¡Œä»»åŠ¡æ‰§è¡Œ
3. ä¸“ä¸šä»£ç†çš„ä½¿ç”¨
4. ä¸Šä¸‹æ–‡å…±äº«å’Œç»“æœæ•´åˆ

ç‰ˆæœ¬ï¼š0.6.0
"""

import asyncio
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from mini_agent import Agent
from mini_agent.llm import create_llm_client
from mini_agent.tools import BashTool, ReadTool, WriteTool
from mini_agent.orchestration import create_orchestrator
from mini_agent.orchestration.prompts import (
    get_coordinator_prompt,
    CODER_PROMPT,
    DESIGNER_PROMPT,
    RESEARCHER_PROMPT,
    TESTER_PROMPT,
)


async def demo_complex_task():
    """
    æ¼”ç¤ºå¤æ‚ä»»åŠ¡çš„å¤„ç†æµç¨‹
    
    è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†å¦‚ä½•åè°ƒå¤šä¸ªä¸“ä¸šä»£ç†å®Œæˆä¸€ä¸ªå¤æ‚çš„å¼€å‘ä»»åŠ¡ã€‚
    ä»»åŠ¡æ¶‰åŠç ”ç©¶ã€è®¾è®¡å’Œç¼–ç å¤šä¸ªæ–¹é¢ã€‚
    """
    print("=" * 70)
    print("ğŸš€ å¯åŠ¨å¤šä»£ç†åä½œç³»ç»Ÿ - å¤æ‚ä»»åŠ¡æ¼”ç¤º")
    print("=" * 70)
    
    # 1. åˆ›å»º LLM å®¢æˆ·ç«¯
    print("\nğŸ“¦ åˆå§‹åŒ– LLM å®¢æˆ·ç«¯...")
    llm = create_llm_client("anthropic")
    print("âœ… LLM å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
    
    # 2. å®šä¹‰å­ä»£ç†é…ç½®
    print("\nğŸ”§ é…ç½®ä¸“ä¸šå­ä»£ç†...")
    sub_agent_configs = [
        {
            "name": "coder",
            "system_prompt": CODER_PROMPT,
            "tools": [
                BashTool(),
                WriteTool(),
                ReadTool(),
            ],
            "max_steps": 30,
            "workspace": "./workspace/coder",
        },
        {
            "name": "designer",
            "system_prompt": DESIGNER_PROMPT,
            "tools": [
                WriteTool(),
                ReadTool(),
            ],
            "max_steps": 20,
            "workspace": "./workspace/designer",
        },
        {
            "name": "researcher",
            "system_prompt": RESEARCHER_PROMPT,
            "tools": [
                BashTool(),
                WriteTool(),
                ReadTool(),
            ],
            "max_steps": 20,
            "workspace": "./workspace/researcher",
        },
    ]
    print(f"âœ… å·²é…ç½® {len(sub_agent_configs)} ä¸ªä¸“ä¸šä»£ç†: coder, designer, researcher")
    
    # 3. åˆ›å»ºåè°ƒç³»ç»Ÿ
    print("\nğŸ—ï¸ åˆ›å»ºå¤šä»£ç†åè°ƒç³»ç»Ÿ...")
    orchestrator = create_orchestrator(
        main_llm_client=llm,
        sub_agent_configs=sub_agent_configs,
        workspace_dir="./workspace/multi_agent",
        max_steps=50,
    )
    print("âœ… åè°ƒç³»ç»Ÿåˆ›å»ºæˆåŠŸ")
    
    # 4. æäº¤å¤æ‚ä»»åŠ¡
    task = """
    è¯·å¸®æˆ‘å®Œæˆä¸€ä¸ªå®Œæ•´çš„é¡¹ç›®æ¼”ç¤ºï¼š
    
    1. ç ”ç©¶å½“å‰ AI Agent æŠ€æœ¯çš„å‘å±•è¶‹åŠ¿ï¼Œæ•´ç†æˆæŠ¥å‘Šä¿å­˜åˆ° research_report.md
    2. è®¾è®¡ä¸€ä¸ªäº§å“å‘å¸ƒä¼šçš„å®£ä¼ æµ·æŠ¥æ¦‚å¿µï¼Œä¿å­˜åˆ° design_concept.md
    3. ç¼–å†™ä¸€ä¸ªç®€å•çš„ Agent æ¼”ç¤ºç¨‹åºï¼ŒåŒ…å«åŸºç¡€åŠŸèƒ½ï¼Œä¿å­˜åˆ° demo_agent.py
    
    è¯·åè°ƒå„ä¸ªä¸“ä¸šä»£ç†å®Œæˆè¿™äº›ä»»åŠ¡ï¼Œæœ€åç»™æˆ‘ä¸€ä¸ªæ€»ç»“æŠ¥å‘Šã€‚
    """
    
    print("\nğŸ“‹ æäº¤å¤æ‚ä»»åŠ¡...")
    print("-" * 50)
    print(task.strip())
    print("-" * 50)
    
    # 5. æ‰§è¡Œä»»åŠ¡
    print("\nâš¡ å¼€å§‹æ‰§è¡Œä»»åŠ¡...")
    result = await orchestrator.execute_task(task)
    
    print("\n" + "=" * 70)
    print("âœ… å¤æ‚ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
    print("=" * 70)
    
    # 6. æŸ¥çœ‹ç»“æœ
    if result.get("success"):
        print(f"\nğŸ“Š æ‰§è¡Œç»“æœ:")
        print(f"   æˆåŠŸ: {result.get('success')}")
        print(f"   ä½¿ç”¨äº† {len(result.get('metadata', {}).get('sub_agents_used', []))} ä¸ªå­ä»£ç†")
        
        print(f"\nğŸ“ ä¸»ä»£ç†å“åº”:")
        print("-" * 50)
        result_content = result.get('result', '')
        if isinstance(result_content, str):
            print(result_content[:1000] + "..." if len(result_content) > 1000 else result_content)
        print("-" * 50)
    else:
        print(f"\nâŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {result.get('error')}")
    
    # 7. æŸ¥çœ‹çŠ¶æ€
    print(f"\nğŸ“ˆ ç³»ç»ŸçŠ¶æ€:")
    status = orchestrator.get_status()
    print(f"   å­ä»£ç†æ•°é‡: {status['sub_agent_count']}")
    print(f"   å­ä»£ç†åˆ—è¡¨: {', '.join(status['sub_agent_names'])}")
    print(f"   ä»»åŠ¡å†å²æ•°: {status['task_history_count']}")
    
    # 8. æŸ¥çœ‹å­ä»£ç†çŠ¶æ€
    print(f"\nğŸ” å­ä»£ç†çŠ¶æ€è¯¦æƒ…:")
    sub_status = orchestrator.get_sub_agent_status()
    for name, info in sub_status.items():
        print(f"   - {name}: {info['message_count']} æ¡æ¶ˆæ¯")
    
    return result


async def demo_parallel_tasks():
    """
    æ¼”ç¤ºå¹¶è¡Œä»»åŠ¡æ‰§è¡Œ
    
    è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†å¦‚ä½•åŒæ—¶æ‰§è¡Œå¤šä¸ªç‹¬ç«‹çš„ä»»åŠ¡ï¼Œ
    å……åˆ†åˆ©ç”¨ç³»ç»Ÿèµ„æºæé«˜æ•ˆç‡ã€‚
    """
    print("\n" + "=" * 70)
    print("ğŸš€ å¯åŠ¨å¹¶è¡Œä»»åŠ¡æ‰§è¡Œæ¼”ç¤º")
    print("=" * 70)
    
    # 1. åˆ›å»º LLM å®¢æˆ·ç«¯
    llm = create_llm_client("anthropic")
    
    # 2. å®šä¹‰å­ä»£ç†
    print("\nğŸ”§ é…ç½®å­ä»£ç†...")
    sub_agent_configs = [
        {
            "name": "coder",
            "system_prompt": CODER_PROMPT,
            "tools": [BashTool(), WriteTool(), ReadTool()],
            "max_steps": 20,
            "workspace": "./workspace/demo/coder",
        },
        {
            "name": "researcher",
            "system_prompt": RESEARCHER_PROMPT,
            "tools": [BashTool(), WriteTool(), ReadTool()],
            "max_steps": 20,
            "workspace": "./workspace/demo/researcher",
        },
    ]
    print("âœ… å·²é…ç½® coder å’Œ researcher ä»£ç†")
    
    orchestrator = create_orchestrator(
        main_llm_client=llm,
        sub_agent_configs=sub_agent_configs,
        workspace_dir="./workspace/demo",
        max_steps=30,
    )
    print("âœ… åè°ƒç³»ç»Ÿåˆ›å»ºæˆåŠŸ")
    
    # 3. å®šä¹‰å¹¶è¡Œä»»åŠ¡
    print("\nğŸ“‹ å®šä¹‰å¹¶è¡Œä»»åŠ¡...")
    tasks = [
        {
            "agent": "coder",
            "task": "åˆ›å»ºä¸€ä¸ª Python è®¡ç®—å™¨ç¨‹åºï¼ŒåŒ…å«åŠ å‡ä¹˜é™¤åŠŸèƒ½ï¼Œä¿å­˜åˆ° calculator.pyã€‚ä»£ç åº”è¯¥ç»“æ„æ¸…æ™°ï¼Œæœ‰é€‚å½“çš„æ³¨é‡Šã€‚",
            "context": {"project": "calculator_demo", "language": "python"},
            "priority": 1,
        },
        {
            "agent": "researcher",
            "task": "ç ”ç©¶ Python ç¼–ç è§„èŒƒï¼ˆå¦‚ PEP 8ï¼‰ï¼Œæ€»ç»“å…³é”®ç‚¹ä¿å­˜åˆ° coding_standards.mdã€‚å†…å®¹åŒ…æ‹¬å‘½åçº¦å®šã€ä»£ç å¸ƒå±€ã€æ³¨é‡Šè§„èŒƒç­‰ã€‚",
            "context": {"project": "calculator_demo"},
            "priority": 1,
        },
    ]
    print(f"âœ… å·²å®šä¹‰ {len(tasks)} ä¸ªå¹¶è¡Œä»»åŠ¡")
    
    # 4. æ‰§è¡Œå¹¶è¡Œä»»åŠ¡
    print("\nâš¡ å¼€å§‹å¹¶è¡Œæ‰§è¡Œ...")
    result = await orchestrator.execute_parallel_tasks(tasks, mode="parallel")
    
    print("\n" + "=" * 70)
    print("âœ… å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå®Œæˆ")
    print("=" * 70)
    
    # 5. æ˜¾ç¤ºæ‰§è¡Œç»“æœ
    print(f"\nğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
    print(f"   æ‰§è¡Œæ¨¡å¼: {result['mode']}")
    print(f"   æ€»ä»»åŠ¡æ•°: {result['total']}")
    print(f"   æˆåŠŸ: {result['success']}")
    print(f"   å¤±è´¥: {result['failed']}")
    print(f"   ä»»åŠ¡åˆ†å¸ƒ: {result['task_breakdown']}")
    print(f"   CPU åˆ©ç”¨ç‡: {result['cpu_utilization']}")
    
    # 6. æ˜¾ç¤ºå„ä»»åŠ¡ç»“æœ
    print(f"\nğŸ“ è¯¦ç»†ç»“æœ:")
    for i, task_result in enumerate(result['results'], 1):
        print(f"\n   ä»»åŠ¡ {i} [{task_result.get('agent', 'unknown')}]")
        print(f"   çŠ¶æ€: {'âœ… æˆåŠŸ' if task_result.get('success') else 'âŒ å¤±è´¥'}")
        print(f"   ç±»å‹: {task_result.get('task_type', 'unknown')}")
        
        if task_result.get('success'):
            content = task_result.get('result', '')
            preview = content[:200] + "..." if len(str(content)) > 200 else content
            print(f"   ç»“æœé¢„è§ˆ: {preview}")
        else:
            print(f"   é”™è¯¯: {task_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    return result


async def demo_simple_delegation():
    """
    æ¼”ç¤ºç®€å•çš„ä»»åŠ¡å§”æ‰˜
    
    å±•ç¤ºå¦‚ä½•ä½¿ç”¨ delegate_to_agent å·¥å…·ç›´æ¥å§”æ‰˜ä»»åŠ¡ã€‚
    """
    print("\n" + "=" * 70)
    print("ğŸš€ å¯åŠ¨ç®€å•ä»»åŠ¡å§”æ‰˜æ¼”ç¤º")
    print("=" * 70)
    
    # 1. åˆ›å»ºåè°ƒå™¨
    llm = create_llm_client("anthropic")
    
    orchestrator = create_orchestrator(
        main_llm_client=llm,
        sub_agent_configs=[
            {
                "name": "coder",
                "system_prompt": CODER_PROMPT,
                "tools": [BashTool(), WriteTool()],
                "max_steps": 10,
                "workspace": "./workspace/simple_coder",
            },
        ],
        workspace_dir="./workspace/simple",
        max_steps=5,
    )
    
    # 2. ç›´æ¥å§”æ‰˜ä»»åŠ¡
    print("\nğŸ“‹ å§”æ‰˜ä»»åŠ¡ç»™ coder ä»£ç†...")
    result = await orchestrator.delegate_task(
        agent_name="coder",
        task="åˆ›å»ºä¸€ä¸ªç®€å•çš„ Python è„šæœ¬ï¼Œè¾“å‡º 'Hello, Multi-Agent World!'ï¼Œä¿å­˜åˆ° hello.py",
        context={"demo": "simple_delegation"},
    )
    
    print("\n" + "=" * 70)
    print("âœ… ä»»åŠ¡å§”æ‰˜å®Œæˆ")
    print("=" * 70)
    
    print(f"\nğŸ“Š æ‰§è¡Œç»“æœ:")
    print(f"   æˆåŠŸ: {result.get('success')}")
    if result.get('success'):
        print(f"   ä»£ç†: {result.get('agent')}")
        print(f"   ç»“æœ: {result.get('result', '')[:200]}...")
    else:
        print(f"   é”™è¯¯: {result.get('error')}")
    
    return result


async def main():
    """
    ä¸»å‡½æ•°
    
    è¿è¡Œæ‰€æœ‰æ¼”ç¤ºã€‚
    """
    print("\n" + "ğŸ”·" * 35)
    print("\n    Mini-Agent v0.6.0 å¤šä»£ç†åè°ƒç³»ç»Ÿæ¼”ç¤º\n")
    print("ğŸ”·" * 35)
    
    # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
    Path("./workspace").mkdir(exist_ok=True)
    Path("./workspace/demo").mkdir(exist_ok=True)
    Path("./workspace/multi_agent").mkdir(exist_ok=True)
    
    try:
        # è¿è¡Œæ¼”ç¤º
        await demo_simple_delegation()
        
        await demo_parallel_tasks()
        
        await demo_complex_task()
        
        print("\n" + "=" * 70)
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 70)
        
        print("\nğŸ“š äº†è§£æ›´å¤š:")
        print("   - æŸ¥çœ‹ docs/PROJECT_IMPROVEMENT_PLAN.md äº†è§£æŠ€æœ¯æ¶æ„")
        print("   - æŸ¥çœ‹ examples/ ç›®å½•è·å–æ›´å¤šç¤ºä¾‹")
        print("   - æŸ¥çœ‹ tests/orchestration/ äº†è§£æµ‹è¯•ç”¨ä¾‹")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
